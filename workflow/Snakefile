
from collections import defaultdict

def read_groups(glob):
    reads ,= glob_wildcards(glob)
    groups = {}
    for read in reads:
        group_name, lane = read.rsplit('_', 1)
        groups[read] = group_name
    return groups

paired = read_groups("rnaseq/paired/{reads}_1.fq.gz")
single = read_groups("rnaseq/single/{reads}_R1_001.fastq.gz")
major_contam ,= glob_wildcards("contamination/major/{query}.fna")
minor_contam ,= glob_wildcards("contamination/minor/{query}.fna")
vir_clades ,= glob_wildcards("viral_elements/{clade}.gff3")
species ,= glob_wildcards("databases/uniprot/species/{species}.fasta")
ref_species ,= glob_wildcards("references/{species}.faa")

lineage = "Viridiplantae"
busco_lineage = "chlorophyta_odb10"
genus_species = "Cymbomonas tetramitiformis"
strain = "PLY_AMNH"

rule all:
    input:
        "output/submission/annot.sqn",
        expand("analysis/busco/run_{lineage}/busco_sequences/single_copy_busco_sequences/", lineage = [ "eukaryota_odb10", "chlorophyta_odb10" ])

rule hisat_index:
    input:
        "analysis/assembly/genome.fa"
    output:
        "analysis/assembly/genome.fa.1.ht2"
    conda:
        "envs/hisat2.yaml"
    shell:
        "hisat2-build {input} {input}"

rule star_index:
    input:
        "analysis/assembly/genome.fa"
    output:
        directory("analysis/star/genome")
    conda:
        "envs/star.yaml"
    shell:
        "STAR --genomeSAindexNbases 10 --runMode genomeGenerate --genomeFastaFiles {input} --genomeDir {output}"

rule hisat_map_single:
    input:
        genome = "analysis/assembly/genome.fa",
        index = "analysis/assembly/genome.fa.1.ht2",
        reads = "analysis/rnaseq/trimmed/single/{reads}_R1_001_trimmed.fq.gz"
    output:
        "analysis/hisat/single/{reads}.bam"
    params:
        sample = lambda w: single[w.reads]
    conda:
        "envs/hisat2.yaml"
    threads:
        10
    shell:
        "hisat2 -x {input.genome} -U {input.reads} --dta --rg-id {wildcards.reads} --rg SM:{params.sample} --rg LB:{params.sample} --rg PL:ILLUMINA -p {threads} | samtools view -bh -F 4 | samtools sort --threads {threads} > {output}"

rule hisat_map_paired:
    input:
        genome = "analysis/assembly/genome.fa",
        index = "analysis/assembly/genome.fa.1.ht2",
        left  = "analysis/rnaseq/trimmed/paired/{reads}_1_val_1.fq.gz",
        right = "analysis/rnaseq/trimmed/paired/{reads}_2_val_2.fq.gz"
    output:
        "analysis/hisat/paired/{reads}.bam"
    params:
        sample = lambda w: paired[w.reads]
    conda:
        "envs/hisat2.yaml"
    threads:
        10
    shell:
        "hisat2 -x {input.genome} -1 {input.left} -2 {input.right} --dta --rg-id {wildcards.reads} --rg SM:{params.sample} --rg LB:{params.sample} --rg PL:ILLUMINA -p {threads} | samtools view -bh -F 4 | samtools sort --threads {threads} > {output}"

rule star_map_single:
    input:
        index = "analysis/star/genome",
        reads = expand("analysis/rnaseq/trimmed/single/{reads}_R1_001_trimmed.fq.gz", reads = single.keys())
    output:
        "analysis/star/single.Aligned.sortedByCoord.out.bam"
    params:
        prefix = "analysis/star/single",
        reads = lambda w, input: ','.join(input.reads),
        groups = lambda w: ' , '.join([ "ID:%s SM:%s" % (ID, SM) for ID, SM in single.items() ])
    conda:
        "envs/star.yaml"
    threads:
        20
    shell:
        "STAR --runThreadN {threads} --outSAMstrandField intronMotif --genomeDir {input.index} --readFilesCommand zcat --readFilesIn {params.reads} --outSAMattrRGline {params.groups} --outFileNamePrefix {params.prefix}. --outSAMtype BAM SortedByCoordinate"

rule star_map_paired:
    input:
        index = "analysis/star/genome",
        left  = expand("analysis/rnaseq/trimmed/paired/{reads}_{side}_val_{side}.fq.gz", reads = paired.keys(), side = 1),
        right = expand("analysis/rnaseq/trimmed/paired/{reads}_{side}_val_{side}.fq.gz", reads = paired.keys(), side = 2)
    output:
        "analysis/star/paired.Aligned.sortedByCoord.out.bam"
    params:
        prefix = "analysis/star/paired",
        left = lambda w, input: ','.join(input.left),
        right = lambda w, input: ','.join(input.right),
        groups = lambda w: ' , '.join([ "ID:%s SM:%s" % (ID, SM) for ID, SM in paired.items() ])
    conda:
        "envs/star.yaml"
    threads:
        20
    shell:
        "STAR --runThreadN {threads} --outSAMstrandField intronMotif --genomeDir {input.index} --readFilesCommand zcat --readFilesIn {params.left} {params.right} --outSAMattrRGline {params.groups} --outFileNamePrefix {params.prefix}. --outSAMtype BAM SortedByCoordinate"

rule trim_paired:
    input:
        "rnaseq/paired/{reads}_1.fq.gz",
        "rnaseq/paired/{reads}_2.fq.gz"
    output:
        "analysis/rnaseq/trimmed/paired/{reads}_1_val_1.fq.gz",
        "analysis/rnaseq/trimmed/paired/{reads}_2_val_2.fq.gz"
    params:
        dirname = "analysis/rnaseq/trimmed/paired"
    conda:
        "envs/trim_galore.yaml"
    shell:
        "trim_galore --paired {input} -o {params.dirname}"

rule trim_single:
    input:
        "rnaseq/single/{reads}_R1_001.fastq.gz"
    output:
        "analysis/rnaseq/trimmed/single/{reads}_R1_001_trimmed.fq.gz"
    params:
        dirname = "analysis/rnaseq/trimmed/single"
    shell:
        "trim_galore {input} -o {params.dirname}"

rule miniprot_index:
    input:
        "analysis/assembly/genome.fa"
    output:
        "analysis/assembly/genome.fa.mpi"
    conda:
        "envs/miniprot.yaml"
    threads:
        10
    shell:
        "miniprot -t{threads} -d {output} {input}"

rule miniprot:
    input:
        db = "analysis/assembly/genome.fa.mpi",
        query = "references/{species}.faa"
    output:
        "analysis/miniprot/references/{species}.gff"
    log:
        "analysis/miniprot/references/{species}.gff.log"
    conda:
        "envs/miniprot.yaml"
    threads:
        5
    shell:
        "miniprot -t{threads} --gff {input.db} {input.query} > {output} 2> {log}"

rule miniprot_mrna:
    input:
        expand("analysis/miniprot/references/{species}.gff", species = ref_species)
    output:
        "analysis/miniprot/references-mrna.gff"
    params:
        ident = 0.5
    conda:
        "envs/tools.yaml"
    shell:
        "cat {input} | filter-gff values --str-eq feat_type:mRNA --num-ge Identity:{params.ident} > {output}"

rule miniprot_mapped:
    input:
        gff = "analysis/miniprot/references-mrna.gff",
        query = expand("references/{species}.faa", species = ref_species)
    output:
        "analysis/miniprot/references.faa"
    conda:
        "envs/tools.yaml"
    shell:
        "get-gff-info mongodb {input.gff} | jq -r .Target | cut -f1 -d' ' | uniq | seqkit grep -f- {input.query} | seqkit replace -p '[*]' | seqkit seq -i -o {output}"

rule miniprot_cdhit:
    input:
        "analysis/miniprot/references.faa"
    output:
        "analysis/miniprot/references.cdhit"
    log:
        "analysis/miniprot/references.cdhit.log"
    params:
        c = 0.9
    conda:
        "envs/tools.yaml"
    shell:
        "cdhit -d 0 -c {params.c} -i {input} -o {output} 2> {log}"

rule miniprot_bed:
    input:
        "analysis/miniprot/references-mrna.gff"
    output:
        "analysis/miniprot/references-mrna.gff.bed"
    conda:
        "envs/tools.yaml"
    shell:
        "bedtools sort -i {input} | bedtools merge > {output}"

rule link_genome:
    input:
        "assembly"
    output:
        "analysis/assembly/genome.fa"
    shell:
        "ln -rs {input}/* {output}"

rule red:
    input:
        "analysis/assembly/genome.fa"
    output:
        sco = "analysis/red/sco/genome.scr",
        cnd = "analysis/red/cnd/genome.cnd",
        rpt = "analysis/red/rpt/genome.bed",
        msk = "analysis/red/msk/genome.msk",
        tbl = "analysis/red/red.tbl",
        hmm = "analysis/red/red.hmm"
    params:
        genome = "analysis/assembly",
        scodir = "analysis/red/sco",
        cnddir = "analysis/red/cnd",
        rptdir = "analysis/red/rpt",
        mskdir = "analysis/red/msk"
    conda:
        "envs/red.yaml"
    shell:
        """
        mkdir -p {params.scodir} {params.cnddir} {params.rptdir} {params.mskdir}
        Red -gnm {params.genome} -tbl {output.tbl} -hmo {output.hmm} -sco {params.scodir} -cnd {params.cnddir} -rpt {params.rptdir} -msk {params.mskdir} -frm 2
        """

rule makeblastdb:
    input:
        "analysis/assembly/genome.fa"
    output:
        "analysis/assembly/genome.fa.ndb"
    conda:
        "envs/blast.yaml"
    shell:
        "makeblastdb -in {input} -dbtype nucl"

rule blast_contam:
    input:
        db = "analysis/assembly/genome.fa",
        ndb = "analysis/assembly/genome.fa.ndb",
        query = "contamination/{query}.fna"
    output:
        "analysis/contamination/{query}.blast6"
    params:
        evalue = 1e-20
    conda:
        "envs/blast.yaml"
    shell:
        "blastn -query {input.query} -db {input.db} -evalue {params.evalue} -outfmt 6 -out {output}"

rule bed_contam:
    input:
        "analysis/contamination/{query}.blast6"
    output:
        "analysis/contamination/{query}.blast6.gff"
    conda:
        "envs/tools.yaml"
    shell:
        "csvcut -t -c2,1,3-6,9,10,7,8,11,12 {input} | csvformat -T | blast2gff blastdb -n > {output}"

rule bed_contam_merge:
    input:
        major = expand("analysis/contamination/major/{query}.blast6.gff", query = major_contam),
        minor = expand("analysis/contamination/minor/{query}.blast6.gff", query = minor_contam)
    output:
        "analysis/contamination/all.bed"
    conda:
        "envs/tools.yaml"
    shell:
        "cat {input} | bedtools sort | bedtools merge > {output}"

rule mask_bed:
    input:
        assembly = "analysis/assembly/genome.fa",
        red_bed  = "analysis/red/rpt/genome.bed",
        homologs = "analysis/miniprot/references-mrna.gff.bed",
        viruses  = expand("viral_elements/{clade}.gff3", clade = vir_clades),
        contam   = expand("analysis/contamination/major/{query}.blast6.gff", query = major_contam)
    output:
        "analysis/mask/masked.bed"
    conda:
        "envs/tools.yaml"
    shell:
        """
        bedtools merge \
                -i <(bedtools subtract -a {input.red_bed} -b {input.homologs}) \
                -i <(cat {input.contam}  | bedtools sort) \
                -i <(cat {input.viruses} | bedtools sort) \
        > {output}
        """

rule mask_fasta:
    input:
        fasta = "analysis/assembly/genome.fa",
        bed = "analysis/mask/masked.bed"
    output:
        "analysis/mask/masked.fasta"
    conda:
        "envs/tools.yaml"
    shell:
        "bedtools maskfasta -soft -fi {input.fasta} -bed {input.bed} -fo {output}"

# not used
rule braker:
    input:
        masked = "analysis/mask/masked.fasta",
        paired = expand("analysis/hisat/paired/{reads}.bam", reads = paired.keys()),
        single = expand("analysis/hisat/single/{reads}.bam", reads = single.keys()),
        homologs = "analysis/miniprot/references.cdhit"
    output:
        gtf = "analysis/braker3/braker.gtf",
        faa = "analysis/braker3/braker.aa",
        dirname = directory("analysis/braker3")
    log:
        "analysis/braker3.log"
    params:
        gc_prob = 0.01,
        paired = lambda w, input: ','.join(input.paired),
        single = lambda w, input: ','.join(input.single)
    singularity:
        "docker://teambraker/braker3"
    shell:
        "braker.pl --genome {input.masked} --species $(date +%s) --bam {params.paired},{params.single} --prot_seq {input.homologs} --workingdir {output.dirname} --threads 1 --softmasking --gc_probability {params.gc_prob} &> {log}"

rule braker_legacy:
    input:
        masked = "analysis/mask/masked.fasta",
        paired = expand("analysis/hisat/paired/{reads}.bam", reads = paired.keys()),
        single = expand("analysis/hisat/single/{reads}.bam", reads = single.keys()),
        homologs = "analysis/miniprot/references.cdhit"
    output:
        "analysis/braker/braker.gtf"
    log:
        "analysis/braker.log"
    params:
        gc_prob = 0.01,
        paired = lambda w, input: ','.join(input.paired),
        single = lambda w, input: ','.join(input.single)
    threads:
        10
    shell:
        "braker --etpmode --genome {input.masked} --species $(date +%s) --bam {params.paired},{params.single} --prot_seq {input.homologs} --workingdir $(dirname {output}) --threads {threads} --softmasking --gc_probability {params.gc_prob} &> {log}"

rule braker_parse_old:
    input:
        gtf = "analysis/braker/braker.gtf",
        fna = "analysis/assembly/genome.fa",
        fix_gff = "workflow/lib/fix_gff_old.py"
    output:
        "analysis/braker/braker_old.gff",
    log:
        "analysis/braker_parse.log"
    conda:
        "envs/gff.yaml"
    shadow:
        "minimal"
    shell:
        """
        (gffread {input.gtf} | awk '$3!~/CDS/' | gt gff3 -sort | gt cds -matchdescstart -seqfile {input.fna} | gffread --keep-genes | python {input.fix_gff} > tmp.gff) 2> {log}
        gfftk sanitize -f {input.fna} -g tmp.gff -o {output}
        """

rule braker_parse:
    input:
        gtf = "analysis/braker/braker.gtf",
        fna = "analysis/assembly/genome.fa"
    output:
        "analysis/braker/braker.gff"
    params:
        fix_gff = "workflow/lib/fix_gff.py"
    log:
        "analysis/braker_parse.log"
    conda:
        "envs/gff.yaml"
    shell:
        """
        (gffread {input.gtf} | awk '$3!~/CDS/' | gt gff3 -sort | gt cds -matchdescstart -seqfile {input.fna} | gffread -FMKYQ | python {params.fix_gff} > {output}_unsanitized.gff) 2> {log}
        gfftk sanitize -f {input.fna} -g {output}_unsanitized.gff -o {output}
        """

rule gff_to_faa:
    input:
        fna = "analysis/assembly/genome.fa",
        gff = "analysis/braker/braker.gff"
    output:
        "analysis/braker/braker.faa"
    conda:
        "envs/gff.yaml"
    shell:
        "gfftk convert -f {input.fna} -i {input.gff} --input-format gff3 --output-format proteins -o {output}"

rule rem_stops:
    input:
        "analysis/braker/braker.faa"
    output:
        "analysis/braker/braker_nostop.faa"
    conda:
        "envs/tools.yaml"
    shell:
        "seqkit replace -sp '[*]$' -o {output} {input}"

rule trna:
    input:
        "analysis/assembly/genome.fa"
    output:
        tab = "analysis/ncrna/trna.tab",
        sec = "analysis/ncrna/trna.sec"
    log:
        "analysis/ncrna/trna.log"
    conda:
        "envs/trnascan.yaml"
    shell:
        "tRNAscan-SE -o {output.tab} -f {output.sec} {input} &> {log}"

rule rrna:
    input:
        fasta = "analysis/assembly/genome.fa",
        cm = "databases/Rfam/Rfam.cm",
        clanin = "databases/Rfam/Rfam.clanin"
    output:
        txt = "analysis/ncrna/rrna.txt",
        tblout = "analysis/ncrna/rrna.tblout"
    log:
        "analysis/ncrna/rrna.log"
    conda:
        "envs/infernal.yaml"
    threads:
        4
    shell:
        "cmscan --cpu {threads} --cut_ga --rfam --nohmmonly --clanin {input.clanin} --oskip --fmt 2 -o {output.txt} --tblout {output.tblout} databases/Rfam/Rfam.cm {input.fasta} &> {log}"

rule busco:
    input:
        "output/submission/annot.faa"
        # "analysis/braker/braker.faa"
    output:
        "analysis/busco/run_{lineage}/full_table.tsv",
        "analysis/busco/short_summary.specific.{lineage}.busco.txt",
        directory("analysis/busco/logs_{lineage}"),
        directory("analysis/busco/run_{lineage}/busco_sequences/single_copy_busco_sequences/")
    params:
        dir = "analysis/busco"
    shadow:
        "minimal"
    conda:
        "envs/busco.yaml"
    threads:
        10
    shell:
        """
        busco --lineage_dataset {wildcards.lineage} -f -i {input} -o busco -m protein -c {threads}
        mv busco/logs busco/logs_{wildcards.lineage}
        rsync -qav busco/ {params.dir}
        """

# NB: not used
rule proteinortho:
    input:
        expand("analysis/species/{species}.fasta", species = species)
    output:
        "analysis/proteinortho/proteinortho.proteinortho.tsv"
    shadow:
        "minimal"
    params:
        dir = "analysis/proteinortho",
        evalue = 1e-5
    threads:
        30
    conda:
        "envs/proteinortho.yaml"
    shell:
        """
        proteinortho -project=proteinortho -cpus={threads} -e={params.evalue} {input}
        mv proteinortho.* {params.dir}
        """

rule dload_eggnog:
    output:
        "analysis/eggnog/data/eggnog.db"
    params:
        taxid = 33090,
        taxon = "Viridiplantae"
    conda:
        "envs/eggnog.yaml"
    shell:
        "download_eggnog_data.py -y -d {params.taxid} --dbname {params.taxon} --data_dir $(dirname {output})"

rule eggnog:
    input:
        db = "analysis/eggnog/data/eggnog.db",
        faa = "analysis/braker/braker_nostop.faa"
    output:
        "analysis/eggnog/emapper/eggnog.emapper.annotations"
    params:
        taxon = lineage
    conda:
        "envs/eggnog.yaml"
    threads:
        20
    shell:
        "emapper.py --cpu {threads} -o eggnog -i {input.faa} --tax_scope {params.taxon} --data_dir $(dirname {input.db}) -m diamond --output_dir $(dirname {output})"

rule interproscan:
    input:
        "analysis/braker/braker_nostop.faa"
    output:
        "analysis/interproscan/braker_nostop.faa.xml"
    params:
        dir = "analysis/interproscan"
    threads:
        20
    shell:
        "interproscan.sh --disable-precalc -i {input} -d {params.dir} -cpu {threads}"

rule funannotate_setup:
    output:
        info = "analysis/funannotate/data/funannotate-db-info.txt",
        ncbi = "analysis/funannotate/data/ncbi_cleaned_gene_products.txt.original"
    params:
        dirname = "analysis/funannotate/data"
    log:
        "analysis/funannotate/funannotate-setup.log"
    shadow:
        "minimal"
    conda:
        "envs/funannotate.yaml"
    shell:
        """
        funannotate setup -w -d {params.dirname} --busco_db eukaryota
        mv funannotate-setup.log {log}
        mv {params.dirname}/ncbi_cleaned_gene_products.txt {output.ncbi}
        """

rule braker_makeblast:
    input:
        "analysis/braker/braker_nostop.faa"
    output:
        "analysis/braker/braker_nostop.faa.pdb"
    conda:
        "envs/blast.yaml"
    shell:
        "makeblastdb -in {input} -dbtype prot"

rule funannotate_dload_busco:
    output:
        "analysis/funannotate/data/{lineage}"
    params:
        host_dir = "https://busco-data.ezlab.org/v5/data/lineages/"
    shell:
        """
        wget -r -np -nH -e robots=off --cut-dirs=5 -A '{wildcards.lineage}.*.tar.gz' {params.host_dir}
        tar xfz {wildcards.lineage}.*.tar.gz -C $(dirname {output})/
        """

rule funannotate_update_products:
    input:
        origin = "analysis/funannotate/data/ncbi_cleaned_gene_products.txt.original",
        custom = "metadata/ncbi_cleaned_gene_products_custom.txt"
    output:
        "analysis/funannotate/data/ncbi_cleaned_gene_products.txt"
    shell:
        "cat <(grep '^#' {input.origin}) <(cat {input.custom}) <(grep -v '^#' {input.origin}) > {output}"

rule funannotate_busco:
    input:
        data = "analysis/funannotate/data/{lineage}".format(lineage = busco_lineage),
        faa = "analysis/braker/braker_nostop.faa"
    output:
        directory("analysis/funannotate/results/annotate_misc/run_busco")
    shadow:
        "minimal"
    conda:
        "envs/funannotate.yaml"
    threads:
        10
    shell:
        """
        $CONDA_PREFIX/lib/python*/site-packages/funannotate/aux_scripts/funannotate-BUSCO2.py -i {input.faa} -m proteins -l {input.data} -o busco -c {threads} -f
        mv run_busco {output}
        """

rule funannotate:
    input:
        iprscan = "analysis/interproscan/braker_nostop.faa.xml",
        eggnog = "analysis/eggnog/emapper/eggnog.emapper.annotations",
        busco = "analysis/funannotate/results/annotate_misc/run_busco",
        gff = "analysis/braker/braker.gff",
        fasta = "analysis/assembly/genome.fa",
        ncbi = "analysis/funannotate/data/ncbi_cleaned_gene_products.txt",
        info = "analysis/funannotate/data/funannotate-db-info.txt"
    output:
        dirname = directory("analysis/funannotate/results/annotate_results"),
        tbl = "analysis/funannotate/results/annotate_results/{species}_{strain}.tbl".format(species = genus_species.replace(' ', '_'), strain = strain)
    log:
        "analysis/funannotate/funannotate-annotate.log"
    params:
        species = genus_species,
        strain = strain,
        lineage = busco_lineage,
        datadir = "analysis/funannotate/data"
    conda:
        "envs/funannotate.yaml"
    threads:
        10
    shell:
        """
        FUNANNOTATE_DB={params.datadir} funannotate annotate -o $(dirname {output.dirname}) --cpus {threads} --rename 1 \
            --species '{params.species}' --strain '{params.strain}' --busco_db {params.lineage} \
            --fasta {input.fasta} --gff {input.gff} -d {params.datadir} --eggnog {input.eggnog} --iprscan {input.iprscan} &> {log}
        """

rule collect_annotations:
    input:
        tbl = "analysis/funannotate/results/annotate_results/{species}_{strain}.tbl".format(species = genus_species.replace(' ', '_'), strain = strain),
        trna = "analysis/ncrna/trna.sec",
        rrna = "analysis/ncrna/rrna.tblout",
        fsa = "analysis/assembly/genome.fa",
        contamination = "analysis/contamination/all.bed"
    output:
        tbl = "output/submission/annot.tbl",
        fsa = "output/submission/annot.fsa"
    params:
        contam_threshold = 0.6,
        trna_threshold = 30,
        trna_software = "tRNAscan-SE:2.0.11",
        rrna_threshold = 1e-10,
        rrna_software = "infernal:1.1.4",
        rrna_database = "Rfam:14.9",
        species = genus_species,
        strain = strain
    conda:
        "envs/biopython.yaml"
    script:
        "scripts/annotations.py"

rule table2asn:
    input:
        tbl = "output/submission/annot.tbl",
        fsa = "output/submission/annot.fsa",
        sbt = "metadata/submission/template.sbt",
        cmt = "metadata/submission/comment.cmt",
        txt = "metadata/submission/comment.txt"
    output:
        sqn = "output/submission/annot.sqn",
        gbf = "output/submission/annot.gbf"
    shell:
        "table2asn -t {input.sbt} -indir $(dirname {output.sqn}) -w {input.cmt} -V b -Y {input.txt} -M n -Z -gaps-min 10 -l paired-ends"

rule fix_gbk:
    input:
        "output/submission/annot.gbf"
    output:
        "output/submission/annot_fixed.gbf"
    shell:
        """
        awk 't{{gsub("-","X")}}  /"/{{t=0}} /translation=/ {{t=1}} 1' {input} > {output}
        """

rule gbf_to_faa:
    input:
        "output/submission/annot_fixed.gbf"
    output:
        "output/submission/annot.faa"
    params:
        biotags = "workflow/lib/biotags.pl",
        species = genus_species
    shell:
        """
        perl {params.biotags} -i {input} -p CDS -t protein_id,product,translation | sed s/ncbi:// | awk -F\\\\t -vs={params.species:q} '{{printf">%s %s [%s]\\n%s\\n",$1,$2,s,$3}}' | seqkit seq > {output}
        """

rule genomad_init:
    output:
        directory("analysis/genomad/data")
    conda:
        "envs/genomad.yaml"
    shell:
        "genomad download-dataset $(dirname {output})"

rule genomad_run:
    input:
        db = "analysis/genomad/data",
        fasta = "analysis/assembly/genome.fa"
    output:
        directory("analysis/genomad/results")
    conda:
        "envs/genomad.yaml"
    threads:
        40
    shell:
        "genomad end-to-end {input.fasta} {output} {input.db}"
